{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-HS-tMiBCjk"
      },
      "source": [
        "# 2CS-SIL2/SIQ2 Lab04. Naïve Bayes\n",
        "\n",
        "<p style='text-align: right;font-style: italic;'>Designed by: Mr. Abdelkrime Aries</p>\n",
        "\n",
        "In this lab, we will learn about Naive Bayes by testing 2 implementations:\n",
        "- Multinomial Naïve Bayes\n",
        "- Gaussian Naïve Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgbzuontBCjm"
      },
      "source": [
        "**Team:**\n",
        "- **Member 01**: AMOURA YOUSRA\n",
        "- **Member 02**: OUADI AMINA TINHINENE\n",
        "- **Group**: SIQ2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vZgeTCW0BCjm",
        "outputId": "cea73c79-810f-4851-b086-4365174de621"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys, timeit\n",
        "from typing          import Tuple, List, Type\n",
        "from collections.abc import Callable\n",
        "\n",
        "sys.version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGiSJ0OuBCjn",
        "outputId": "3221a7c5-96cb-41eb-f7c4-3505e05c93dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('2.0.2', '2.2.2', '3.10.0')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy             as np\n",
        "import pandas            as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "np.__version__, pd.__version__, matplotlib.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5q2pUQAoBCjo",
        "outputId": "a7988217-360a-4ed2-ce07-66251e7db8a5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.6.1'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "from sklearn.naive_bayes   import CategoricalNB\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics       import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection         import train_test_split\n",
        "from sklearn.naive_bayes             import MultinomialNB, GaussianNB\n",
        "from sklearn.linear_model            import LogisticRegression\n",
        "from sklearn.tree                    import DecisionTreeClassifier\n",
        "from sklearn.metrics                 import precision_score, recall_score\n",
        "import timeit\n",
        "\n",
        "\n",
        "sklearn.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btviGy9ABCjo"
      },
      "source": [
        "## I. Algorithms implementation\n",
        "\n",
        "In this section, we will try to implement multinomial Naive Bayes.\n",
        "\n",
        "\n",
        "**>> Try to use \"numpy\" which will save a lot of time and effort**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxGyFNwgBCjo",
        "outputId": "e8c167e5-00b7-4953-e516-8262fec2dcfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14, 14)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dataset play\n",
        "\n",
        "# outlook & temperature & humidity & windy\n",
        "Xplay = np.array([\n",
        "    ['sunny'   , 'hot' , 'high'  , 'no'],\n",
        "    ['sunny'   , 'hot' , 'high'  , 'yes'],\n",
        "    ['overcast', 'hot' , 'high'  , 'no'],\n",
        "    ['rainy'   , 'mild', 'high'  , 'no'],\n",
        "    ['rainy'   , 'cool', 'normal', 'no'],\n",
        "    ['rainy'   , 'cool', 'normal', 'yes'],\n",
        "    ['overcast', 'cool', 'normal', 'yes'],\n",
        "    ['sunny'   , 'mild', 'high'  , 'no'],\n",
        "    ['sunny'   , 'cool', 'normal', 'no'],\n",
        "    ['rainy'   , 'mild', 'normal', 'no'],\n",
        "    ['sunny'   , 'mild', 'normal', 'yes'],\n",
        "    ['overcast', 'mild', 'high'  , 'yes'],\n",
        "    ['overcast', 'hot' , 'normal', 'no'],\n",
        "    ['rainy'   , 'mild', 'high'  , 'yes']\n",
        "])\n",
        "\n",
        "Yplay = np.array([\n",
        "    'no',\n",
        "    'no',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'no',\n",
        "    'yes',\n",
        "    'no',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'no'\n",
        "])\n",
        "\n",
        "len(Xplay), len(Yplay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDrrN5lIBCjp",
        "outputId": "970035f2-08dc-46a8-af69-8ccb3f4899ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8, 8)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# height & weight & footsize & person\n",
        "Xperson = np.array([\n",
        "    [182., 81.6, 30.],\n",
        "    [180., 86.2, 28.],\n",
        "    [170., 77.1, 30.],\n",
        "    [180., 74.8, 25.],\n",
        "    [152., 45.4, 15.],\n",
        "    [168., 68.0, 20.],\n",
        "    [165., 59.0, 18.],\n",
        "    [175., 68.0, 23.]\n",
        "])\n",
        "\n",
        "Yperson = np.array([\n",
        "    'male', 'male', 'male', 'male',\n",
        "    'female', 'female', 'female', 'female'\n",
        "])\n",
        "\n",
        "len(Xperson), len(Yperson)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoB8C9cNBCjp"
      },
      "source": [
        "### I.1. Prior statistics\n",
        "\n",
        "Given an output list $Y[M]$, the probability of each class $c$ is estimated as:\n",
        "$$p(c) = \\frac{\\#(Y = c)}{|Y|}$$\n",
        "\n",
        "In here, we want to store the frequencies of different classes.\n",
        "Our function must return two lists:\n",
        "- One containing the names of unique classes.\n",
        "- Another containing their frequencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J3vdfSHBCjp",
        "outputId": "784e2022-4da2-4e44-d510-6964319a02fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((array(['no', 'yes'], dtype='<U3'), array([5, 9])),\n",
              " (array(['female', 'male'], dtype='<U6'), array([4, 4])))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: Prior statistics\n",
        "def fit_prior(Y: np.ndarray[str]) -> Tuple[np.ndarray[str], np.ndarray[int]]:\n",
        "    c, f = np.unique(Y, return_counts=True)\n",
        "    return c, f\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# ((array(['no', 'yes'], dtype='<U3'), array([5, 9])),\n",
        "#  (array(['female', 'male'], dtype='<U6'), array([4, 4])))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "fit_prior(Yplay), fit_prior(Yperson)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXmWDNu5BCjq"
      },
      "source": [
        "### I.2. Multinomial Law\n",
        "\n",
        "In this section, we will implement multinomial naive Bayes from scratch using Numpy.\n",
        "\n",
        "#### I.2.1. Multinomial Likelihood statistics\n",
        "\n",
        "Given:\n",
        "- $A$: a categorical feature\n",
        "- $Y$: the ouput\n",
        "- $C$: the classes\n",
        "\n",
        "The function takes as argument $A, Y, C$ previously described.\n",
        "It must return:\n",
        "- $V$: unique values of this feature (feature's categories)\n",
        "- $S[|C|, |V|]$: a matrix containing count $\\#(Y = c \\wedge A = v),\\, \\forall c \\in C, \\forall v \\in A$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5JBUuUEBCjq",
        "outputId": "e781d1e4-f43a-4bd2-b0d6-d0b379d9b1c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((array(['overcast', 'rainy', 'sunny'], dtype='<U8'),\n",
              "  array([[0, 2, 3],\n",
              "         [4, 3, 2]])),\n",
              " (array(['cool', 'hot', 'mild'], dtype='<U8'),\n",
              "  array([[1, 2, 2],\n",
              "         [3, 2, 4]])))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: Multinomial Likelihood statistics\n",
        "def fit_multinomial_likelihood(A: np.ndarray[str],\n",
        "                               Y: np.ndarray[str],\n",
        "                               C: np.ndarray[str]\n",
        "                               ) -> Tuple[np.ndarray[str], np.ndarray[int]]:\n",
        "    V = np.unique(A)\n",
        "    S = np.zeros((len(C), len(V)), dtype=int)\n",
        "\n",
        "    # Populate the count matrix S\n",
        "    for i, c in enumerate(C):\n",
        "        for j, v in enumerate(V):\n",
        "            S[i, j] = np.sum((Y == c) & (A == v))\n",
        "\n",
        "    return V, S\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# ((array(['overcast', 'rainy', 'sunny'], dtype='<U8'),\n",
        "#   array([[0, 2, 3],\n",
        "#          [4, 3, 2]])),\n",
        "#  (array(['cool', 'hot', 'mild'], dtype='<U8'),\n",
        "#   array([[1, 2, 2],\n",
        "#          [3, 2, 4]])))\n",
        "#---------------------------------------------------------------------\n",
        "C_t = np.array(['no', 'yes'])\n",
        "fit_multinomial_likelihood(Xplay[:, 0], Yplay, C_t), fit_multinomial_likelihood(Xplay[:, 1], Yplay, C_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFdUxX1RBCjq"
      },
      "source": [
        "#### I.2.2. Multinomial Likelihood training\n",
        "\n",
        "**Nothing to code here, although you have to know how it functions for next use**\n",
        "\n",
        "This function aims to generate parameters $\\theta$.\n",
        "In our case, paramters are diffrent from those of *logistic regrssion*.\n",
        "They are a dictionary (map) with two entries:\n",
        "- \"prior\": a dictionary having \"vocab\" a list of values and \"freq\" a list of their respective frequencies.\n",
        "- \"likelihood\": a list of dictionaries representing statistics of each feature (the same order of $X$ features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7TImbAyBCjq",
        "outputId": "fe0c1045-d4b6-470e-db97-0ee0ef8d2bc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prior': {'vocab': array(['no', 'yes'], dtype='<U3'), 'freq': array([5, 9])},\n",
              " 'likelihood': [{'vocab': array(['overcast', 'rainy', 'sunny'], dtype='<U8'),\n",
              "   'freq': array([[0, 2, 3],\n",
              "          [4, 3, 2]])},\n",
              "  {'vocab': array(['cool', 'hot', 'mild'], dtype='<U8'),\n",
              "   'freq': array([[1, 2, 2],\n",
              "          [3, 2, 4]])},\n",
              "  {'vocab': array(['high', 'normal'], dtype='<U8'),\n",
              "   'freq': array([[4, 1],\n",
              "          [3, 6]])},\n",
              "  {'vocab': array(['no', 'yes'], dtype='<U8'),\n",
              "   'freq': array([[2, 3],\n",
              "          [6, 3]])}]}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def fit_multinomial_NB(X: 'np.ndarray[M, N](str)',\n",
        "                       Y: 'np.ndarray[M](str)'\n",
        "                       ) -> object:\n",
        "\n",
        "    Theta   = {'prior': {}, 'likelihood': []}\n",
        "\n",
        "    Theta['prior']['vocab'], Theta['prior']['freq'] = fit_prior(Y)\n",
        "\n",
        "    for j in range(X.shape[1]):\n",
        "        likelihood = {}\n",
        "        likelihood['vocab'], likelihood['freq'] = fit_multinomial_likelihood(X[:, j], Y, Theta['prior']['vocab'])\n",
        "        Theta['likelihood'].append(likelihood)\n",
        "\n",
        "    return Theta\n",
        "\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# {'prior': {'vocab': array(['no', 'yes'], dtype='<U3'), 'freq': array([5, 9])},\n",
        "#  'likelihood': [{'vocab': array(['overcast', 'rainy', 'sunny'], dtype='<U8'),\n",
        "#    'freq': array([[0, 2, 3],\n",
        "#           [4, 3, 2]])},\n",
        "#   {'vocab': array(['cool', 'hot', 'mild'], dtype='<U8'),\n",
        "#    'freq': array([[1, 2, 2],\n",
        "#           [3, 2, 4]])},\n",
        "#   {'vocab': array(['high', 'normal'], dtype='<U8'),\n",
        "#    'freq': array([[4, 1],\n",
        "#           [3, 6]])},\n",
        "#   {'vocab': array(['no', 'yes'], dtype='<U8'),\n",
        "#    'freq': array([[2, 3],\n",
        "#           [6, 3]])}]}\n",
        "#---------------------------------------------------------------------\n",
        "Theta_play = fit_multinomial_NB(Xplay, Yplay)\n",
        "\n",
        "Theta_play"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM-igIgUBCjr"
      },
      "source": [
        "#### I.2.3. Multinomial Likelihood prediction\n",
        "\n",
        "Given:\n",
        "- $A$: a categorical feature\n",
        "- $V$: unique values of this feature (feature's categories)\n",
        "- $Y$: the ouput\n",
        "- $C$: the classes\n",
        "- $\\alpha$: smoothing factor\n",
        "\n",
        "Log likelihood is calculated as:\n",
        "$$ \\log p(A=v|Y=c) = \\log(\\#(Y = k \\wedge A = v) + \\alpha) - \\log(\\#(y = k) + \\alpha * |V|)$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aszTaG0YBCjr",
        "outputId": "727d559c-e26f-4629-a667-28167923b355"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(np.int64(1), -1)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can use this function in the next implimentation\n",
        "# It takes a list of unique values V and a given value v\n",
        "# It returns the position of v in V\n",
        "# If v does not exist in V, it rturns -1\n",
        "def find_idx(V: np.ndarray, v: str) -> int:\n",
        "    k = np.argwhere(V == v).flatten()\n",
        "    if len(k):\n",
        "        return k[0]\n",
        "    return -1\n",
        "\n",
        "V_t = np.array(['One', 'Two', 'Three'])\n",
        "find_idx(V_t, 'Two'), find_idx(V_t, 'Four')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1jv3R2tBCjr",
        "outputId": "442ffce6-c53a-4be3-d14d-60103e02f344"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([-0.91629073, -1.09861229]), array([-2.07944154, -2.48490665]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: Multinomial Likelihood prediction\n",
        "def predict_multinomial_NB1(v: str,\n",
        "                            j: int,\n",
        "                            Theta: object,\n",
        "                            alpha: float = 0.\n",
        "                            ) -> np.ndarray[float]:\n",
        "    feature_likelihood = Theta['likelihood'][j]\n",
        "    V = feature_likelihood['vocab']\n",
        "    S = feature_likelihood['freq']\n",
        "\n",
        "    v_idx = find_idx(V, v)\n",
        "\n",
        "    P = Theta['prior']['freq']\n",
        "\n",
        "    Result = np.zeros(S.shape[0])\n",
        "\n",
        "    for i in range(S.shape[0]):\n",
        "        count = S[i, v_idx] if v_idx != -1 else 0\n",
        "        count += alpha\n",
        "\n",
        "        total = P[i] + alpha * len(V)\n",
        "\n",
        "        Result[i] = np.log(count) - np.log(total)\n",
        "\n",
        "    return Result\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# (array([-0.91629073, -1.09861229]), array([-2.07944154, -2.48490665]))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "X_t = np.array([\n",
        "    ['rainy', 'cool', 'normal', 'yes'],\n",
        "    ['snowy', 'cool', 'normal', 'yes'],\n",
        "    ['sunny', 'hot' , 'normal', 'no']\n",
        "])\n",
        "\n",
        "predict_multinomial_NB1('rainy', 0, Theta_play, alpha=0.), \\\n",
        "    predict_multinomial_NB1('snowy', 0, Theta_play, alpha=1.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxzIj8MyBCjr"
      },
      "source": [
        "### I.3. Normal (Gaussian) Law\n",
        "\n",
        "In this section, we will implement gaussian naive Bayes from scratch using Numpy.\n",
        "\n",
        "#### I.3.1. Gaussian Likelihood statistics\n",
        "\n",
        "Given:\n",
        "- $A$: a categorical feature\n",
        "- $Y$: the ouput\n",
        "- $C$: the classes\n",
        "\n",
        "The function takes as argument $A, Y, C$ previously described.\n",
        "It must return $S[|C|, 2, N]$; a tensor having these dimensions:\n",
        "- first dimension: each element represents one class's statistics\n",
        "- second dimension: 1st element represents means; 2ns element represents variances\n",
        "- third dimension: each element represents mean/variance of the respective feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPmWXOo0BCjs",
        "outputId": "c9bbb082-1890-4a7f-9e39-5a0415d968c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[165.        ,  60.1       ,  19.        ],\n",
              "        [ 92.66666667, 114.04      ,  11.33333333]],\n",
              "\n",
              "       [[178.        ,  79.925     ,  28.25      ],\n",
              "        [ 29.33333333,  25.47583333,   5.58333333]]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: Gaussian Likelihood statistics\n",
        "def fit_gaussian_likelihood(X: np.ndarray[float],\n",
        "                            Y: np.ndarray[str],\n",
        "                            C: np.ndarray[str]\n",
        "                            ) -> Tuple['np.ndarray[C, 2, N](float)']:\n",
        "    Nb_C = len(C)\n",
        "    Nb_F = X.shape[1]\n",
        "\n",
        "\n",
        "    S = np.zeros((Nb_C, 2, Nb_F))\n",
        "\n",
        "    for i, yi in enumerate(C):\n",
        "\n",
        "        x = X[Y == yi]\n",
        "\n",
        "        means = np.mean(x, axis=0)\n",
        "\n",
        "        variances = np.var(x, axis=0, ddof=1)\n",
        "\n",
        "        S[i, 0, :] = means\n",
        "        S[i, 1, :] = variances\n",
        "\n",
        "    return S\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# array([[[165.        ,  60.1       ,  19.        ],\n",
        "#         [ 92.66666667, 114.04      ,  11.33333333]],\n",
        "\n",
        "#        [[178.        ,  79.925     ,  28.25      ],\n",
        "#         [ 29.33333333,  25.47583333,   5.58333333]]])\n",
        "#---------------------------------------------------------------------\n",
        "C_t = np.array(['female', 'male'])\n",
        "fit_gaussian_likelihood(Xperson, Yperson, C_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwmBDaC3BCjs"
      },
      "source": [
        "#### I.3.2. Gaussian Likelihood training\n",
        "\n",
        "**Nothing to code here, although you have to know how it functions for next use**\n",
        "\n",
        "This function aims to generate parameters $\\theta$.\n",
        "In our case, paramters are diffrent from those of *logistic regrssion*.\n",
        "They are a dictionary (map) with two entries:\n",
        "- \"prior\": a dictionary having \"vocab\" a list of values and \"freq\" a list of their respective frequencies.\n",
        "- \"likelihood\": a tensor of shape $[|C|, 2, N]$ containing likelihood statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVE4K3pFBCjs",
        "outputId": "2bfd1f3a-fd9d-42da-d0ae-d241a177bf76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prior': {'vocab': array(['female', 'male'], dtype='<U6'),\n",
              "  'freq': array([4, 4])},\n",
              " 'likelihood': array([[[165.        ,  60.1       ,  19.        ],\n",
              "         [ 92.66666667, 114.04      ,  11.33333333]],\n",
              " \n",
              "        [[178.        ,  79.925     ,  28.25      ],\n",
              "         [ 29.33333333,  25.47583333,   5.58333333]]])}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def fit_gaussian_NB(X: np.ndarray[str, str],\n",
        "                    Y: np.ndarray[str]\n",
        "                    ) -> object:\n",
        "\n",
        "    Theta   = {'prior': {}, 'likelihood': []}\n",
        "\n",
        "    Theta['prior']['vocab'], Theta['prior']['freq'] = fit_prior(Y)\n",
        "    Theta['likelihood'] = fit_gaussian_likelihood(X, Y, Theta['prior']['vocab'])\n",
        "\n",
        "    return Theta\n",
        "\n",
        "\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# {'prior': {'vocab': array(['female', 'male'], dtype='<U6'),\n",
        "#   'freq': array([4, 4])},\n",
        "#  'likelihood': array([[[165.        ,  60.1       ,  19.        ],\n",
        "#          [ 92.66666667, 114.04      ,  11.33333333]],\n",
        "\n",
        "#         [[178.        ,  79.925     ,  28.25      ],\n",
        "#          [ 29.33333333,  25.47583333,   5.58333333]]])}\n",
        "#---------------------------------------------------------------------\n",
        "Theta_person = fit_gaussian_NB(Xperson, Yperson)\n",
        "\n",
        "Theta_person"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7ZIzGUmBCjs"
      },
      "source": [
        "#### I.2.4. Gaussian Likelihood prediction\n",
        "\n",
        "Given:\n",
        "- $A$: a numerical feature\n",
        "- $\\mu_{Ac}$: mean of values of feature $A$ having $c$ as class\n",
        "- $\\sigma_{Ac}$: variance of values of feature $A$ having $c$ as class\n",
        "- $Y$: the output\n",
        "- $C$: the classes\n",
        "\n",
        "Log likelihood is calculated as:\n",
        "$$ \\log p(A=v|Y=c) = \\frac{-(v-\\mu_{Ac})^2}{2 \\sigma_{Ac}^2} - \\log(\\sqrt{2\\pi \\sigma_{Ac}^2})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMAWiUuiBCjt",
        "outputId": "96afe6a8-e66f-4fea-cdb8-565c33ca3723"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([-4.93164438, -3.03443716]), array([0.00721463, 0.04810173]))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: Gaussian Likelihood prediction\n",
        "def predict_gaussian_NB1(v: str,\n",
        "                         j: int,\n",
        "                         Theta: object,\n",
        "                         alpha: float = 0. # this is just added for compatibility\n",
        "                         ) -> np.ndarray[float]:\n",
        "\n",
        "    C = Theta['prior']['vocab']\n",
        "\n",
        "    M_V = Theta['likelihood']\n",
        "\n",
        "    Log_likelihood = []\n",
        "\n",
        "    for i, yi in enumerate(C):\n",
        "\n",
        "        mean = M_V[i][0][j]\n",
        "        variance = M_V[i][1][j]\n",
        "\n",
        "        Log_p = - ((v - mean) ** 2) / (2 * variance) - np.log(np.sqrt(2 * np.pi * variance))\n",
        "\n",
        "        Log_likelihood.append(Log_p)\n",
        "\n",
        "    return np.array(Log_likelihood)\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# (array([-4.93164438, -3.03443716]), array([0.00721463, 0.04810173]))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "pp = predict_gaussian_NB1(183, 0, Theta_person)\n",
        "\n",
        "pp, np.exp(pp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B-ngqRoBCjt"
      },
      "source": [
        "### I.4. Final prediction\n",
        "\n",
        "Our goal is to calculate approximate log probabilities of all classes given a sample:\n",
        "$$\\log P(y=c_k | \\overrightarrow{x} = \\overrightarrow{f})  \\approx \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j = x_j|y=c_k)$$\n",
        "\n",
        "This function takes:\n",
        "- $X^{(i)}$ one sample with $N$ features\n",
        "- $\\theta$ parameters (either those of multinomial or gaussian)\n",
        "- $pred_{fct}$ a function to predict one feauture (either multinomial or gaussian)\n",
        "- add_prior: if True, add prior probability\n",
        "- $\\alpha$ smoothing factor (passing it to gaussian function will do nothing)\n",
        "\n",
        "It must return a vector of probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxQI3ycmBCjt",
        "outputId": "64f0d2fa-c145-456f-ce7d-cc88a5ef2705"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([-3.59617006, -4.95406494]),\n",
              " array([-2.56655064, -4.51223219]),\n",
              " array([-2.85774653, -4.23617476]),\n",
              " array([-10.401093  , -22.03977023]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: Final prediction\n",
        "def predict_NB1(Xi    : 'np.ndarray[N]',\n",
        "                Theta: object,\n",
        "                pred_fct: Callable,\n",
        "                add_prior: bool  = True,\n",
        "                alpha: float = 1.0\n",
        "                ) -> np.ndarray[float]:\n",
        "    Nb_C = len(Theta['prior']['vocab'])\n",
        "\n",
        "    log_p = np.zeros(Nb_C)\n",
        "\n",
        "    for i in range(Nb_C):\n",
        "        if add_prior:\n",
        "            prior_prob = np.log(Theta['prior']['freq'][i] / np.sum(Theta['prior']['freq']))\n",
        "            log_p[i] += prior_prob\n",
        "\n",
        "        for j in range(len(Xi)):\n",
        "            log_likelihood = pred_fct(Xi[j], j, Theta, alpha)\n",
        "            log_p[i] += log_likelihood[i]\n",
        "\n",
        "    return log_p\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# (array([-2.20940778, -3.86937505]),\n",
        "#  array([-2.56655064, -4.51223219]),\n",
        "#  array([-2.85774653, -4.23617476]),\n",
        "#  array([-10.401093  , -22.03977023]))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "X_t1 = np.array(['sunny', 'hot' , 'high', 'no'])\n",
        "X_t2 = np.array([183., 59., 20.])\n",
        "\n",
        "predict_NB1(X_t1, Theta_play, predict_multinomial_NB1, add_prior=True, alpha=0.0), \\\n",
        "predict_NB1(X_t1, Theta_play, predict_multinomial_NB1, add_prior=False, alpha=0.0), \\\n",
        "predict_NB1(X_t1, Theta_play, predict_multinomial_NB1, add_prior=False, alpha=1.0), \\\n",
        "predict_NB1(X_t2, Theta_person, predict_gaussian_NB1, add_prior=False),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7rlc9NBCjt"
      },
      "source": [
        "### I.5. Final product\n",
        "\n",
        "**>> Nothing to code here**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64cdoUZ9BCjt",
        "outputId": "10f2a48a-028a-4711-dc1c-7879c7a467b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['yes', 'yes', 'no'], dtype='<U3'),\n",
              " array([[-5.20912179, -4.10264337],\n",
              "        [-6.30773408, -5.48893773],\n",
              "        [-3.88736595, -4.67800751]]),\n",
              " array(['female', 'male'], dtype='<U6'),\n",
              " array([[-11.09424018, -22.73291741],\n",
              "        [-15.27968966, -12.41764665]]))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class NaiveBayes(object):\n",
        "\n",
        "    def __init__(self, multinomial=True):\n",
        "        if multinomial:\n",
        "            self.train = fit_multinomial_NB\n",
        "            self.pred = predict_multinomial_NB1\n",
        "        else:\n",
        "            self.train = fit_gaussian_NB\n",
        "            self.pred = predict_gaussian_NB1\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.Theta = self.train(X, Y)\n",
        "\n",
        "    def predict(self, X, add_prior=True, prob=False, alpha=0.):\n",
        "        Y_pred = []\n",
        "        for i in range(len(X)):\n",
        "            Y_pred.append(predict_NB1(\n",
        "                X[i,:], self.Theta, self.pred, add_prior=add_prior, alpha=alpha\n",
        "                ))\n",
        "\n",
        "        Y_pred = np.array(Y_pred)\n",
        "\n",
        "        if prob:\n",
        "            return Y_pred\n",
        "\n",
        "        return np.choose(np.argmax(Y_pred, axis=1), self.Theta['prior']['vocab'])\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# (array(['yes', 'yes', 'no'], dtype='<U3'),\n",
        "#  array([[-3.82235951, -3.01795347],\n",
        "#         [-4.9209718 , -4.40424783],\n",
        "#         [-2.50060367, -3.59331761]]),\n",
        "#  array(['female', 'male'], dtype='<U6'),\n",
        "#  array([[ -9.901093  , -21.53977023],\n",
        "#         [-14.08654248, -11.22449947]]))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "multinomial_nb = NaiveBayes()\n",
        "multinomial_nb.fit(Xplay, Yplay)\n",
        "\n",
        "gaussian_nb = NaiveBayes(multinomial=False)\n",
        "gaussian_nb.fit(Xperson, Yperson)\n",
        "\n",
        "X_t1 = np.array([\n",
        "    ['rainy', 'cool', 'normal', 'yes'],\n",
        "    ['snowy', 'cool', 'normal', 'yes'],\n",
        "    ['sunny', 'hot' , 'high', 'no']\n",
        "])\n",
        "\n",
        "X_t2 = np.array([\n",
        "    [183., 59., 20.],\n",
        "    [175., 65., 30.]\n",
        "])\n",
        "\n",
        "\n",
        "multinomial_nb.predict(X_t1, alpha=1.), \\\n",
        "    multinomial_nb.predict(X_t1, alpha=1., prob=True), \\\n",
        "    gaussian_nb.predict(X_t2), \\\n",
        "    gaussian_nb.predict(X_t2, prob=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtnVQVEeBCju"
      },
      "source": [
        "## II. Application and Analysis\n",
        "\n",
        "In this section, we will test different concepts by running an experiment, formulating a hypothesis and trying to justify it.\n",
        "\n",
        "### II.1. Prior probability\n",
        "\n",
        "We want to test the effect of prior probability.\n",
        "To do this, we trained two models:\n",
        "1. With prior probability\n",
        "1. Without prior probability (It considers a uniform distribution of classes)\n",
        "\n",
        "To test whether the models have adapted well to the training dataset, we will test them on the same dataset and calculate the classification ratio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTJiq0NZBCju",
        "outputId": "360034ef-05a2-40df-b7df-db57195c9110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Considring prior probability\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "No prior probability\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.67      0.80      0.73         5\n",
            "         yes       0.88      0.78      0.82         9\n",
            "\n",
            "    accuracy                           0.79        14\n",
            "   macro avg       0.77      0.79      0.78        14\n",
            "weighted avg       0.80      0.79      0.79        14\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nb_withPrior     = CategoricalNB(alpha=1.0, fit_prior=True )\n",
        "nb_noPrior       = CategoricalNB(alpha=1.0, fit_prior=False)\n",
        "\n",
        "enc         = OrdinalEncoder()\n",
        "Xplay_tf    = enc.fit_transform(Xplay)\n",
        "nb_withPrior.fit(Xplay_tf, Yplay)\n",
        "nb_noPrior.fit(Xplay_tf, Yplay)\n",
        "\n",
        "Ypred_withPrior = nb_withPrior.predict(Xplay_tf)\n",
        "Ypred_noPrior = nb_noPrior.predict(Xplay_tf)\n",
        "\n",
        "\n",
        "print( 'Considring prior probability'  )\n",
        "print(classification_report(Yplay, Ypred_withPrior))\n",
        "\n",
        "print( 'No prior probability'  )\n",
        "print(classification_report(Yplay, Ypred_noPrior))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sbU0uukBCjv"
      },
      "source": [
        "**TODO: Analyze the results**\n",
        "\n",
        "1. What do you notice, indicating if prior probability is useful in this case?\n",
        "1. How does this probability affect the outcome?\n",
        "1. When are we sure that using this probability is unnecessary?\n",
        "\n",
        "**Answer**\n",
        "\n",
        "1. In this case, considering prior probability clearly improves the model’s performance:\n",
        "- Accuracy increases significantly (93% vs 79%)\n",
        "- Precision and Recall for both classes become much better\n",
        "- F1-score also increases, reflecting a better balance between precision and recall\n",
        "\n",
        "This indicates that the model, when using the prior, correctly takes into account the imbalance between the \"yes\" and \"no\" classes, leading to more reliable and balanced predictions.\n",
        "\n",
        "2. The incorporation of prior probability influences the outcome by assigning greater importance to classes that are more common in the dataset. Without considering prior probability, the model incorrectly assumes that all classes occur equally often. By including prior information, the model better matches the real class distribution, naturally favoring more frequent classes, and thus can influence the classification of new examples toward those more likely classes.\n",
        "3. Using prior probability is unnecessary when:\n",
        "- The dataset is perfectly balanced (each class has roughly the same number of examples)\n",
        "- Or when the features are so strong and discriminative that they alone are enough to make accurate predictions, regardless of any class imbalance.\n",
        "\n",
        "In such cases, adding prior information would not significantly impact the model’s performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuUxDP90BCjv"
      },
      "source": [
        "### II.2. Smoothing\n",
        "\n",
        "We want to test the Lidstone smoothing's effect.\n",
        "To do this, we trained three models:\n",
        "1. alpha = 1 (Laplace smoothing)\n",
        "1. alpha = 0.5\n",
        "1. alpha = 0 (without smoothing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnjTqlkjBCjv",
        "outputId": "955a8e8f-fb24-4211-f88e-91da7db1ec51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alpha = 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "Alpha = 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "Alpha = 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py:1528: RuntimeWarning: divide by zero encountered in log\n",
            "  np.log(smoothed_cat_count) - np.log(smoothed_class_count.reshape(-1, 1))\n"
          ]
        }
      ],
      "source": [
        "NBC_10 = CategoricalNB(alpha = 1.0 )\n",
        "NBC_05 = CategoricalNB(alpha = 0.5 )\n",
        "NBC_00 = CategoricalNB(alpha = 0.0 )\n",
        "\n",
        "NBC_10.fit( Xplay_tf,   Yplay )\n",
        "NBC_05.fit( Xplay_tf,   Yplay )\n",
        "NBC_00.fit( Xplay_tf,   Yplay )\n",
        "\n",
        "Y_10   = NBC_10.predict(Xplay_tf)\n",
        "Y_05   = NBC_05.predict(Xplay_tf)\n",
        "Y_00   = NBC_00.predict(Xplay_tf)\n",
        "\n",
        "\n",
        "print(                'Alpha = 1.0'                        )\n",
        "print(classification_report(Yplay, Y_10, zero_division=0.0))\n",
        "\n",
        "print(                'Alpha = 0.5'                        )\n",
        "print(classification_report(Yplay, Y_05, zero_division=0.0))\n",
        "\n",
        "print(                'Alpha = 0.0'                        )\n",
        "print(classification_report(Yplay, Y_00, zero_division=0.0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3NkHLMfBCjw"
      },
      "source": [
        "**TODO: Analyze the results**\n",
        "\n",
        "1. What do you notice, indicating if smoothing affects performance in this case?\n",
        "1. Based on the past answeer, Why?\n",
        "1. Why do we get a \"RuntimeWarning: divide by zero\" error?\n",
        "1. What is the benefit of smoothing (generally; not just for this case)?\n",
        "\n",
        "**Answer**\n",
        "\n",
        "1. In this case, smoothing (whether alpha = 1, 0.5, or 0) does not affect the model’s performance: the precision, recall, f1-score, and accuracy remain exactly the same (93% accuracy, identical scores for each class). This suggests that smoothing has no visible impact here because the model already sees all the possible feature values during training and testing — no unseen feature occurs.\n",
        "1. Smoothing becomes important when we risk encountering feature values that were never seen during training. Since in this dataset every test example only uses feature values that already appeared in the training set, there’s no zero probability problem to fix. Therefore, smoothing does not help nor hurt: it simply has no effect because the data is “complete” from the model’s point of view.\n",
        "1. The \"RuntimeWarning: divide by zero\" happens when we use alpha = 0 (no smoothing) and try to take the logarithm of a zero probability. If a feature value was not seen for a particular class during training, the model estimates P(feature | class) = 0, and log(0) is undefined mathematically (it tends toward minus infinity), which causes the warning.\n",
        "1. Smoothing ensures that the model never assigns zero probability to any event, even unseen ones. This makes the classifier more robust, especially when dealing with small datasets, rare feature values, or new situations in testing. Even if the training data misses some possibilities, smoothing allows the model to still handle them reasonably without collapsing predictions to zero probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIAEpFCwBCjw"
      },
      "source": [
        "### II.3. Naive Bayes performance\n",
        "\n",
        "*   Élément de liste\n",
        "*   Élément de liste\n",
        "\n",
        "\n",
        "\n",
        "Naive Bayes is known to generate powerful models when it comes to classifying textual documents.\n",
        "We want to test this proposition using spam detection over [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset) dataset.\n",
        "\n",
        "Each message is represented using term frequency (TF), where a word is considered as a feature.\n",
        "In this case, a message is represented by a vector of frequencies (how many times each word appeared in the message).\n",
        "We want to compare these models:\n",
        "1. Multinomial Naive Bayes (MNB)\n",
        "1. Gaussian Naive Bayes (GNB)\n",
        "1. Logistic Regression (LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "04xvddecBCjw",
        "outputId": "868afc52-e2e1-40e5-c41b-51998ed57f96"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"messages\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"Did u download the fring app?\",\n          \"Pass dis to all ur contacts n see wat u get! Red;i'm in luv wid u. Blue;u put a smile on my face. Purple;u r realy hot. Pink;u r so swt. Orange;i thnk i lyk u. Green;i realy wana go out wid u. Yelow;i wnt u bck. Black;i'm jealous of u. Brown;i miss you Nw plz giv me one color\",\n          \"Ok...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "messages"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-aacbef33-8300-4683-84e1-2d2d8617c74c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aacbef33-8300-4683-84e1-2d2d8617c74c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aacbef33-8300-4683-84e1-2d2d8617c74c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aacbef33-8300-4683-84e1-2d2d8617c74c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c508d2bf-e044-4d0c-8348-5daf3158be17\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c508d2bf-e044-4d0c-8348-5daf3158be17')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c508d2bf-e044-4d0c-8348-5daf3158be17 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text class\n",
              "0  Go until jurong point, crazy.. Available only ...   ham\n",
              "1                      Ok lar... Joking wif u oni...   ham\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
              "3  U dun say so early hor... U c already then say...   ham\n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# reading the dataset\n",
        "messages = pd.read_csv('data/spam.csv', encoding='latin-1')\n",
        "# renaming features: text and class\n",
        "messages = messages.rename(columns={'v1': 'class', 'v2': 'text'})\n",
        "# keeping only these two features\n",
        "messages = messages.filter(['text', 'class'])\n",
        "\n",
        "messages.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "wGZObtT7BCjw",
        "outputId": "085c1b56-ecc7-4248-bb82-874599b2bc71"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"})\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Algorithm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Multinomial Naive Bayes (MNB)\",\n          \"Gaussian Naive Bayes  (GNB)\",\n          \"Logistic Regression (LR)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23853934910564525,\n        \"min\": 0.6752341619999811,\n        \"max\": 1.1517128130000174,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9341890510000326,\n          0.6752341619999811,\n          1.1517128130000174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06070338531068388,\n        \"min\": 0.03349697900000592,\n        \"max\": 0.14254228800001556,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.04179687499998863,\n          0.14254228800001556,\n          0.03349697900000592\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21360793100235972,\n        \"min\": 0.6166666666666667,\n        \"max\": 0.9871794871794872,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9871794871794872,\n          0.6166666666666667,\n          0.9861111111111112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03614457831325302,\n        \"min\": 0.8554216867469879,\n        \"max\": 0.927710843373494,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.927710843373494,\n          0.891566265060241,\n          0.8554216867469879\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1616bf77-ea9a-4562-9627-af8275240090\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Train time</th>\n",
              "      <th>Test time</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Multinomial Naive Bayes (MNB)</td>\n",
              "      <td>0.934189</td>\n",
              "      <td>0.041797</td>\n",
              "      <td>0.987179</td>\n",
              "      <td>0.927711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gaussian Naive Bayes  (GNB)</td>\n",
              "      <td>0.675234</td>\n",
              "      <td>0.142542</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>0.891566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic Regression (LR)</td>\n",
              "      <td>1.151713</td>\n",
              "      <td>0.033497</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.855422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1616bf77-ea9a-4562-9627-af8275240090')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1616bf77-ea9a-4562-9627-af8275240090 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1616bf77-ea9a-4562-9627-af8275240090');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0aec1215-bbb5-4e06-bc72-5e0af83515d3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0aec1215-bbb5-4e06-bc72-5e0af83515d3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0aec1215-bbb5-4e06-bc72-5e0af83515d3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                       Algorithm  Train time  Test time  Precision    Recall\n",
              "0  Multinomial Naive Bayes (MNB)    0.934189   0.041797   0.987179  0.927711\n",
              "1    Gaussian Naive Bayes  (GNB)    0.675234   0.142542   0.616667  0.891566\n",
              "2       Logistic Regression (LR)    1.151713   0.033497   0.986111  0.855422"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models = [\n",
        "    MultinomialNB(),\n",
        "    GaussianNB(),\n",
        "    LogisticRegression(solver='lbfgs'),\n",
        "    #solver=sag is slower; so I chose the fastest\n",
        "]\n",
        "\n",
        "algos = [\n",
        "    'Multinomial Naive Bayes (MNB)',\n",
        "    'Gaussian Naive Bayes  (GNB)',\n",
        "    'Logistic Regression (LR)',\n",
        "]\n",
        "\n",
        "perf = {\n",
        "    'train_time': [],\n",
        "    'test_time' : [],\n",
        "    'recall'    : [],\n",
        "    'precision' : []\n",
        "}\n",
        "\n",
        "\n",
        "msg_train, msg_test, Y_train, Y_test = train_test_split(messages['text'] ,\n",
        "                                                        messages['class'],\n",
        "                                                        test_size    = 0.2,\n",
        "                                                        random_state = 0  )\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "X_train          = count_vectorizer.fit_transform(msg_train).toarray()\n",
        "X_test           = count_vectorizer.transform    (msg_test ).toarray()\n",
        "\n",
        "\n",
        "for model in models:\n",
        "    # ==================================\n",
        "    # TRAIN\n",
        "    # ==================================\n",
        "    start_time = timeit.default_timer()\n",
        "    model.fit(X_train, Y_train)\n",
        "    perf['train_time'].append(timeit.default_timer() - start_time)\n",
        "\n",
        "    # ==================================\n",
        "    # TEST\n",
        "    # ==================================\n",
        "    start_time = timeit.default_timer()\n",
        "    Y_pred     = model.predict(X_test)\n",
        "    perf['test_time'].append(timeit.default_timer() - start_time)\n",
        "\n",
        "    # ==================================\n",
        "    # PERFORMANCE\n",
        "    # ==================================\n",
        "    # In here, we are interrested in \"spam\" class which is our positive class\n",
        "    perf['precision'].append(precision_score(Y_test, Y_pred, pos_label='spam'))\n",
        "    perf['recall'   ].append(recall_score   (Y_test, Y_pred, pos_label='spam'))\n",
        "\n",
        "\n",
        "pd.DataFrame({\n",
        "    'Algorithm' : algos,\n",
        "    'Train time': perf['train_time'],\n",
        "    'Test time' : perf['test_time'],\n",
        "    'Precision' : perf['precision'],\n",
        "    'Recall'    : perf['recall']\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MK7C5eyBCjx"
      },
      "source": [
        "**TODO: Analyze the results**\n",
        "\n",
        "1. What do you notice about training time? (order the algorithms)\n",
        "1. Why did we get these results based on the algorithms? (discuss each algorithm with respect to training time)\n",
        "1. What do you notice about the testing time? (order the algorithms)\n",
        "1. Why did we get these results based on the algorithms? (discuss each algorithm with respect to testing time)\n",
        "1. Why is the Gaussian model less efficient than the multinomial based on the nature of the two algorithms?\n",
        "1. Why is the Gaussian model less efficient than the multinomial based on the nature of the problem/data?\n",
        "1. How Multinomial NB's implementation affect the training/test time? (store statistics vs. store probabilities)\n",
        "1. Which one is more adequate for updating the model with new data? explain.\n",
        "\n",
        "**Answer**\n",
        "\n",
        "1. The order from fastest to slowest training time is Gaussian Naive Bayes (GNB), then Multinomial Naive Bayes (MNB), and finally Logistic Regression (LR). GNB trains the fastest (~ 0.67s), followed by MNB (~ 0.93s), and LR is the slowest (~1.15s).\n",
        "1. Gaussian Naive Bayes is faster because it only needs to compute simple statistics (mean and variance) for each feature and class. Multinomial Naive Bayes, while simple, has to count and smooth word occurrences across classes, which takes a bit longer. Logistic Regression requires iterative optimization (gradient descent), which is more computationally heavy, explaining why it trains the slowest.\n",
        "1. The order from fastest to slowest test time is Logistic Regression (LR), then Multinomial Naive Bayes (MNB), and finally Gaussian Naive Bayes (GNB). LR is extremely fast to predict (~ 0.033s), followed by MNB (~ 0.041s), and GNB is the slowest (~0.142s).\n",
        "1. Logistic Regression is fast at prediction because it simply computes a weighted sum and applies a sigmoid threshold. MNB is also fast but must multiply many small probabilities for each feature, which takes a bit more time. GNB is the slowest because it needs to compute a Gaussian probability density function (involving exponentials and divisions) for each feature and class at prediction time, which is heavier.\n",
        "1. Gaussian Naive Bayes must handle continuous data, requiring more complex mathematical operations like exponentials and divisions for each prediction, while Multinomial Naive Bayes only performs simple integer counting and multiplication, making it fundamentally lighter and faster for discrete/counted features.\n",
        "1. The dataset consists of text data transformed into count vectors (integer frequencies), which naturally fits the multinomial model. Gaussian Naive Bayes assumes real-valued, continuous, normally distributed features — which is not true for text — so it struggles to model the data efficiently, making it less accurate and computationally heavier in this case.\n",
        "1. Multinomial Naive Bayes stores simple count statistics during training (how many times each word appears per class) and converts them into log-probabilities. Because these are precomputed and stored efficiently, predictions only involve summing log-probabilities, making both training and testing extremely fast compared to methods that recompute complex functions during prediction.\n",
        "1. Multinomial Naive Bayes is more adequate for updating with new data because it only needs to increment word counts for each class and recompute probabilities, without retraining the whole model. Logistic Regression and Gaussian Naive Bayes would require a full reoptimization or recalculation of parameters, making online updates much slower or infeasible.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
